{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25bc794a",
   "metadata": {},
   "source": [
    "# Supervised Algorithms Group10 (career recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63d12b8",
   "metadata": {},
   "source": [
    "Our dataset involves career prediction based on historical job titles and skills. This is a classification problem where each data point (skills and job titles) is mapped to a future job title. The choice of Support Vector Machine (SVM) and Random Forest (RF) is justified based on the following factors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30b4c02",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine (SVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92811d66",
   "metadata": {},
   "source": [
    "#### -Handles High-Dimensional Text Data Well: \n",
    "Since we are using TF-IDF vectorization, the features are sparse and high-dimensional. SVM works well in such cases because it finds a hyperplane that maximizes class separation.\n",
    "#### -Good for Small to Medium Datasets: \n",
    "Since our dataset consist of 2000 rows it consider small data set, and SVM is known to work well even with limited training data, making it suitable for our dataset.\n",
    "#### -Robust to Overfitting (with Linear Kernel):\n",
    "Since our features are textual representations, using a linear kernel prevents overfitting while maintaining interpretability.\n",
    "Works Well with Imbalanced Data: SVM is effective when there is class imbalance (some job titles appear much less frequently than others), as it focuses on the hardest-to-classify points near the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5f4559",
   "metadata": {},
   "source": [
    "## 2. Random Forest (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f35d3",
   "metadata": {},
   "source": [
    "#### -Handles Non-Linear Relationships Well: \n",
    "Unlike SVM, which finds a linear decision boundary (unless using kernels), Random Forest can capture complex relationships between job history, skills, and job title.\n",
    "#### -Handles Categorical & Text Features Well: \n",
    "Our dataset has job titles, skills, and employer names, which can be encoded as categorical data or word embeddings.\n",
    "#### -Resistant to Overfitting: \n",
    "Since Random Forest averages multiple decision trees, it reduces the risk of overfitting.\n",
    "#### -Feature Importance: \n",
    "It helps interpret which skills, courses, or past jobs are most important in career recommendations.\n",
    "#### -Works Well with Mixed Data: \n",
    "It handles both numerical (num_skills, num_past_jobs) and categorical (careerjunction_za_skills, careerjunction_za_historical_jobtitles) data efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493c1c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------\n",
    "Now, let's implement both two algorithms and compare results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46719c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed59850",
   "metadata": {},
   "source": [
    "#### 1. LOAD AND CLEAN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a790c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = 'data_science_extract(in).csv'\n",
    "df = pd.read_csv(file_path, encoding=\"latin1\", usecols=[\n",
    "    \"careerjunction_za_future_jobtitles\",\n",
    "    \"careerjunction_za_skills\",\n",
    "    \"careerjunction_za_historical_jobtitles\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d38ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where future job title is missing or empty\n",
    "df.dropna(subset=['careerjunction_za_future_jobtitles'], inplace=True)\n",
    "df = df[df['careerjunction_za_future_jobtitles'].str.strip() != \"[]\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05140746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize target labels (strip whitespace, fix inconsistencies)\n",
    "df['careerjunction_za_future_jobtitles'] = df['careerjunction_za_future_jobtitles'].str.strip()\n",
    "df['careerjunction_za_future_jobtitles'] = df['careerjunction_za_future_jobtitles'].str.replace('\\xa0', ' ', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9404c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert skills & job titles from string representations of lists to actual lists\n",
    "df['careerjunction_za_skills'] = df['careerjunction_za_skills'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "df['careerjunction_za_historical_jobtitles'] = df['careerjunction_za_historical_jobtitles'].apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5083582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to text format\n",
    "df['skills_text'] = df['careerjunction_za_skills'].apply(lambda skills: ' '.join(skills))\n",
    "df['hist_text'] = df['careerjunction_za_historical_jobtitles'].apply(lambda jobs: ' '.join(jobs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe1a74f",
   "metadata": {},
   "source": [
    "####  2. MERGE RARE CLASSES INTO \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba897ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each job title category\n",
    "class_counts = df['careerjunction_za_future_jobtitles'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0374252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold (minimum samples per job title category)\n",
    "min_samples = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "835187a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace rare categories with \"Other\"\n",
    "df['careerjunction_za_future_jobtitles'] = df['careerjunction_za_future_jobtitles'].apply(\n",
    "    lambda x: x if class_counts[x] >= min_samples else \"Other\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abde43",
   "metadata": {},
   "source": [
    "#### 3. SPLIT DATA INTO TRAIN & TEST SETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f395ba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (skills_text + hist_text) and target\n",
    "X = df[['skills_text', 'hist_text']]\n",
    "y = df['careerjunction_za_future_jobtitles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b978ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified train-test split (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b668b38",
   "metadata": {},
   "source": [
    "#### 4. HANDLE CLASS IMBALANCE (OVERSAMPLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0cb9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_train and y_train to resample minority classes\n",
    "train_data = X_train.copy()\n",
    "train_data['future_jobtitle'] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d2e2a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max count of the most common class\n",
    "max_count = train_data['future_jobtitle'].value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "473e78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Perform oversampling for minority classes\n",
    "oversampled_train_parts = []\n",
    "for category, group in train_data.groupby('future_jobtitle'):\n",
    "    if len(group) < max_count:\n",
    "        group_oversampled = resample(group, replace=True, n_samples=max_count, random_state=42)\n",
    "        oversampled_train_parts.append(group_oversampled)\n",
    "    else:\n",
    "        oversampled_train_parts.append(group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae60c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new balanced training set\n",
    "train_data_balanced = pd.concat(oversampled_train_parts).reset_index(drop=True)\n",
    "train_data_balanced = train_data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae1f7871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract oversampled features and labels\n",
    "X_train_balanced = train_data_balanced[['skills_text', 'hist_text']]\n",
    "y_train_balanced = train_data_balanced['future_jobtitle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aaf4f7",
   "metadata": {},
   "source": [
    "#### 5. TEXT FEATURE EXTRACTION (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d0a4e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizers for skills & job titles\n",
    "skills_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "history_vectorizer = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb3cc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform on training data\n",
    "X_train_skill_tfidf = skills_vectorizer.fit_transform(X_train_balanced['skills_text'])\n",
    "X_train_hist_tfidf = history_vectorizer.fit_transform(X_train_balanced['hist_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37381f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "X_test_skill_tfidf = skills_vectorizer.transform(X_test['skills_text'])\n",
    "X_test_hist_tfidf = history_vectorizer.transform(X_test['hist_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d75b4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine TF-IDF matrices\n",
    "X_train_final = hstack([X_train_skill_tfidf, X_train_hist_tfidf])\n",
    "X_test_final = hstack([X_test_skill_tfidf, X_test_hist_tfidf])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7f134e",
   "metadata": {},
   "source": [
    " #### 6. TRAIN & EVALUATE MACHINE LEARNING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5331b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM Classifier\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_final, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1cb2729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_final, y_train_balanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f57e31",
   "metadata": {},
   "source": [
    "#### 7. MODEL PERFORMANCE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1741db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred_svm = svm_model.predict(X_test_final)\n",
    "y_pred_rf = rf_model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d632d542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.4976635514018692\n",
      "Random Forest Accuracy: 0.5397196261682243\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy Scores\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc614b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Classification Report:\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "               Administrative & Support       0.00      0.00      0.00         1\n",
      "         Consulting & Business Analysis       0.09      0.09      0.09        35\n",
      "  Data Analysis & Business Intelligence       0.30      0.32      0.31        38\n",
      "  Database Administration & Development       0.00      0.00      0.00        14\n",
      "          Engineering & Technical Roles       0.00      0.00      0.00        10\n",
      "                   Finance & Accounting       0.00      0.00      0.00         1\n",
      "            IT Support & Administration       0.22      0.18      0.20        39\n",
      "Learning & Development (L&D) / Training       0.00      0.00      0.00         1\n",
      "                                  Other       0.00      0.00      0.00         4\n",
      "                     Project Management       0.36      0.32      0.34        47\n",
      "                      Sales & Marketing       0.36      0.16      0.22        25\n",
      "                   Software Development       0.66      0.83      0.73       207\n",
      "               Web Development & Design       0.50      0.17      0.25         6\n",
      "\n",
      "                               accuracy                           0.50       428\n",
      "                              macro avg       0.19      0.16      0.16       428\n",
      "                           weighted avg       0.44      0.50      0.46       428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hadee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hadee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Print Classification Reports\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "568ca88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Classification Report:\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "               Administrative & Support       0.00      0.00      0.00         1\n",
      "         Consulting & Business Analysis       0.20      0.03      0.05        35\n",
      "  Data Analysis & Business Intelligence       0.61      0.29      0.39        38\n",
      "  Database Administration & Development       0.00      0.00      0.00        14\n",
      "          Engineering & Technical Roles       0.00      0.00      0.00        10\n",
      "                   Finance & Accounting       0.00      0.00      0.00         1\n",
      "            IT Support & Administration       0.00      0.00      0.00        39\n",
      "Learning & Development (L&D) / Training       0.00      0.00      0.00         1\n",
      "                                  Other       0.00      0.00      0.00         4\n",
      "                     Project Management       0.44      0.34      0.39        47\n",
      "                      Sales & Marketing       0.43      0.24      0.31        25\n",
      "                   Software Development       0.56      0.95      0.70       207\n",
      "               Web Development & Design       0.00      0.00      0.00         6\n",
      "\n",
      "                               accuracy                           0.54       428\n",
      "                              macro avg       0.17      0.14      0.14       428\n",
      "                           weighted avg       0.41      0.54      0.44       428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hadee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hadee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\hadee\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRandom Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc74102",
   "metadata": {},
   "source": [
    "Based on the results, Random Forest (53.97%) outperformed SVM (49.77%) in accuracy, making it the better choice for predicting future job titles from skills and historical job data. The main reason for Random Forest’s superior performance is its ability to handle non-linear relationships better than SVM. Career progression is often complex and not strictly linear, and Random Forest, being an ensemble of decision trees, can capture these variations more effectively. Additionally, Random Forest is more robust to noise and outliers, as it averages across multiple trees, reducing the impact of misclassified instances. On the other hand, SVM relies on a linear decision boundary, which may not be the best fit for this type of data. Moreover, even after oversampling, some job categories may still be underrepresented, and Random Forest’s ability to handle imbalanced data through multiple decision paths gives it an advantage over SVM, which tends to struggle with class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668b919",
   "metadata": {},
   "source": [
    "### Reasons for the Obtained Accuracy Values : \n",
    "#### -Class Imbalance in the Dataset:\n",
    "The dataset contains a disproportionate number of samples for different job categories. Some job titles, such as \"Software Development,\" have significantly more occurrences compared to others like \"Finance & Accounting\" or \"Learning & Development.\" This imbalance causes the model to favor predicting the majority classes while failing to correctly classify underrepresented job titles.\n",
    "\n",
    "#### -Overlapping Job Titles and Skills:\n",
    "Many job roles share similar skill sets, making it difficult for the model to distinguish between them. For example, \"Data Analysis & Business Intelligence\" and \"Database Administration & Development\" both require database knowledge, which confuses the model and leads to misclassifications.\n",
    "\n",
    "#### -Limited Feature Representation Using TF-IDF:\n",
    "The model relies on TF-IDF (Term Frequency-Inverse Document Frequency) to represent job skills in a numerical format. However, TF-IDF does not capture semantic relationships between words. For instance, it treats \"Machine Learning\" and \"Artificial Intelligence\" as completely separate terms, even though they are conceptually related. This limitation reduces the model’s ability to generalize well.\n",
    "\n",
    "#### -Insufficient Training Samples for Some Categories:\n",
    "Certain job categories have very few samples in the dataset, leading to zero recall for those classes. Since the model does not encounter enough examples of rare job titles, it struggles to make correct predictions, which is evident in categories like \"Administrative & Support\" and \"Finance & Accounting.\"\n",
    "\n",
    "#### -SVM Struggles with Complex Class Boundaries:\n",
    "Support Vector Machines (SVM) perform best when there is a clear separation between classes. However, due to overlapping skills and job roles in the dataset, SVM fails to define accurate decision boundaries, leading to lower accuracy.\n",
    "\n",
    "#### -Random Forest Performs Better but is Still Biased:\n",
    "Random Forest captures non-linear patterns better than SVM, which is why it achieves higher accuracy. However, it still struggles with underrepresented job categories and tends to favor dominant job titles, causing lower recall for less common roles.\n",
    "\n",
    "#### -Low Macro Average F1-Score Due to Imbalance:\n",
    "The overall performance of the model is negatively affected by the imbalance in job titles, leading to a low macro-average F1-score. The model performs well on frequently occurring job roles but fails to generalize well to less common job categories.\n",
    "\n",
    "------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c4846",
   "metadata": {},
   "source": [
    "#### 8. FUNCTION FOR USER INPUT & PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "763eca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_job(skills, historical_jobs, model_choice='svm'):\n",
    "    \"\"\"Predict future job title based on input skills and historical job titles.\"\"\"\n",
    "\n",
    "    # Convert input lists to text\n",
    "    skills_text = ' '.join(skills)\n",
    "    hist_text = ' '.join(historical_jobs)\n",
    "\n",
    "    # Transform input using trained TF-IDF vectorizers\n",
    "    skills_tfidf = skills_vectorizer.transform([skills_text])\n",
    "    hist_tfidf = history_vectorizer.transform([hist_text])\n",
    "\n",
    "    # Combine feature vectors\n",
    "    input_features = hstack([skills_tfidf, hist_tfidf])\n",
    "\n",
    "    # Predict using selected model\n",
    "    if model_choice == 'svm':\n",
    "        prediction = svm_model.predict(input_features)\n",
    "    elif model_choice == 'rf':\n",
    "        prediction = rf_model.predict(input_features)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model choice. Choose 'svm' or 'rf'.\")\n",
    "\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6938d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analysis & Business Intelligence\n"
     ]
    }
   ],
   "source": [
    "print(predict_future_job([\"Python\", \"Machine Learning\"], [\"Data Analyst\"], model_choice='svm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017ac35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
